# Construcci贸n de Pipeline con YFinance, Airbyte, Clickhouse, DBT y Airflow

Este proyecto tiene como objetivo integrar y validar m煤ltiples fuentes de informaci贸n sobre bancos que cotizan en la bolsa de valores de los Estados Unidos. Se utiliza un pipeline de datos que incluye la extracci贸n de la informaci贸n con Yfinance, un entorno de landing zone en PostgreSQL, un almac茅n OLAP en ClickHouse, herramientas de integraci贸n como Airbyte, validaci贸n y transformaci贸n de datos con DBT, y orquestaci贸n del pipeline con Airflow.

Este es el diagrama de la arquitectura del ETL con las tecnolog铆as utilizadas:

![Arquitectura del ETL](https://github.com/user-attachments/assets/f2a020cf-3519-4836-94e3-f50b94801dad)

Y este est谩 el diagrama del ETL al final de la implementaci贸n desde la vista de grafos del Dag Airflow:

Este es el DAG que ejecuta la extracci贸n y la carga de la data desde el source hasta el stage:
![ELT Dag](https://github.com/user-attachments/assets/f7d53a23-bf82-494f-a6cb-5f03ac15934d)

Este es el DAG que ejecuta las transformaciones con DBT cuando hubo alg煤n cambio en el datawarehouse:
![DBT jobs](https://github.com/user-attachments/assets/e5f1e019-eb41-4c33-8864-d2612c030cd4)


## Tecnolog铆as usadas:
- **PostgreSQL**: Para almacenar datos crudos extra铆dos desde el API.
- **ClickHouse**: Como almac茅n centralizado de datos curados.
- **Airbyte**: Para la integraci贸n de datos entre PostgreSQL y ClickHouse.
- **DBT**: Para validar y transformar los datos.
- **Airflow**: Para orquestar y automatizar el pipeline de datos.
- **yfinance**: Para la extracci贸n de informaci贸n sobre los bancos.

## Requerimientos previos:

Antes de comenzar con esta integraci贸n, aseg煤rate de tener las siguientes instrucciones listas:

1. **Git**: Si no lo tiene instalado, desc谩rgalo e inst谩lalo desde [Git][[https://docs.docker.com/get-docker/](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git)] siguiendo la documentaci贸n oficial para tu Sistema Operativo.

2. **Docker y Docker Compose (Docker Desktop)**: Si no lo tiene instalado, desc谩rgalo e inst谩lalo desde [Docker][https://docs.docker.com/get-docker/] siguiendo la documentaci贸n oficial para tu Sistema Operativo.

## 1. Configurar el ambiente para el proyecto

Descargue el proyecto en su m谩quina local siguiendo estos pasos:

1. **Clona este repositorio**:
   ```bash
   git clone https://github.com/gabrielcepedag/sib.git
   ```
2. **Clona el repositorio de AirByte**:
   ```bash
   git clone https://github.com/airbytehq/airbyte.git
   ```
3. **Crea un archivo .env en la ra铆z del proyecto con estas variables un ejemplo del valor**:
   ```bash
   cd sib/
   ```

   ```bash
   #POSTGRESQL
    DB_HOST=localhost
    POSTGRES_USER=sib_user
    POSTGRES_PASSWORD=sib_user
    POSTGRES_DB=landing_zone
    POSTGRES_PORT=5432
    
    #CLICKHOUSE
    CLICKHOUSE_HTTP_PORT=8123
    CLICKHOUSE_TCP_PORT=9000
    
    #AIRFLOW
    AIRFLOW_DB=airflow
    AIRFLOW_WEB_PORT=8080
    #id - u en el host
    AIRFLOW_UID=501
   ```

### 2. Configurar la red para docker
  
  Dado que el servicio de Airbyte se encuentra en otro proyecto, es necesario crear una red externa de forma que
  desde el contenedor en donde se ejecuta Airflow, se tenga comunicaci贸n con el contenedor que maneja las conexiones
  de Airbyte. Para ello siga los siguientes pasos: 

  1. Crear la red en docker
     
   ```bash
   docker network create airbyte_airflow
   ```

## 3. Ejecutar los contenedores

  En esta paso usted puede proceder con la ejecuci贸n de los contenedores de ambos proyectos para ello, siga las siguientes instrucciones:
     
  1. Correr las dem谩s herramientas:

   ```bash
    cd sib/
   ```
   ```bash
    docker-compose up -d
   ```

   2. Este comando descarga el archivo docker-compose.yaml y corre Airbyte. Por lo tanto, primero lo ejecutamos para descargar el archivo:

   ```bash
    ./airbyte/run-ab-platform.sh
   ```

   3. Luego, agregamos la nueva red en el docker-compose.yml del proyecto de Airbyte como se muestra en adelante:
   
   ```bash
   networks:
    airbyte_airflow:
    external: true
   ```

  3. Agregar la red en el servicio de airbyte-proxy:
   
   ```bash
    airbyte-proxy:
      networks:
      - airbyte_airflow
   ```
   
## 4. Configurar conector de Airbyte desde la UI

Inicia en la UI de Airbyte accediendo a http://localhost:8000/ en tu navegador. El usuario y contrase帽a por defecto es airbyte y password. Luego:

  1. **Crea una fuente (source)**:

   - Ve al apartado de Sources y click en `+ New source`.
   - Busca el conector para `Postgres`.
   - Ajusta los campos seg煤n tus variables de entorno. Una gu铆a puede ser:
     
     ```bash
       host = postgres-db
       port = 5432
       Database Name = landing_zone
       username = sib_user
       password = sib_user
     ```
   - Click en `Set up source`.

2. **Crea un destino**:

   - Ve al apartado de Destinos y click en `+ New destination`.
   - Busca el conector par `Clickhouse`.
    - Ajusta los campos seg煤n tus variables de entorno. Una gu铆a puede ser:
      
     ```bash
       host = localhost
       port = 8123
       DB Name = stage
       user = default
     ```
   - Click en `Set up destination`.

3. **Crear una conexi贸n**:

   - Ve al apartado de Conexiones y click en `+ New connection`.
   - Selecciona la fuente y el destino que acabas de crear.
   - Coloca los detalles de las conexiones como sea necesario.
   - Click en `Set up connection`.

Est谩s listo! Tu conexi贸n est谩 configurada y lista para usarse! 

4. **Copiar Connection-id para poder ejecutar el sync desde Airflow**:

   - En la URL de la conexi贸n copia lo que est谩 luego del path `/connections/`
   - Pega ese ID en la variable de entorno `AIRBYTE_CONNECTION_ID`
   - Reinicia el proyecto principal

    ```bash
    cd sib/
    docker-compose up down
    docker-compose up -d
   ```

## 5. Configurar conector de Airbyte desde la UI en Airflow

Inicia en la UI de Airflow accediendo a http://localhost:8080/ en tu navegador. El usuario y contrase帽a por defecto es airflow. Luego:

   - Ve al apartado de Conexiones y click en `+ New connection`.
   - Elige el tipo de conexi贸n de Airbyte
   - Ajusta los campos con la siguiente guia:
     
     ```bash
       Connection Id = airbyte_conn_id
       host = airbyte-proxy
       login = airbyte
       password = password
       port = 8001
     ```
     
   - Click en `Save`.
## 6. Orquestaci贸n con Airflow

Ahora que todo est谩 configurado, es tiempo de correr el pipeline!

- En la UI de Airflow, ve al apartado de "DAGs"
- Localiza `extract_info_banks_stocks` y click en "Trigger DAG".

Esto iniciar谩 el pipeline completo, comenzando con la extracci贸n de la data desde yfinance, almacenando esa data en PostgreSQL, luego ejecutando el proceso de `sync` de Airbyte para transportar la data cruda desde Postgres a Clickhouse. Y por 煤ltimo, corriendo las validaciones y transformaciones con DBT para tener como resultado la data para ser utilizada por los analistas.

- Confirma el estado de la sincronizaci贸n en Airbyte.
- Luego de que el job `send_to_datawarehouse` se ejecute, puedes observar la data en clickhouse en el esquema definido en la conexi贸n del destino. Si no definiste esquema estar谩 en el esquema `_airbyte_internal_`.
- Una vez que el proceso anterior se complete, se ejecutar谩 un trigger que ejecutar谩 el DAG `execute_dbt_jobs`. Este es el encargado de ejecutar las validaciones y transformaciones de los datos en stage.
- Cuando el proceso anterior culmine, puedes observar en la base de datos de clickhouse en el esquema `dwh` estar谩n los modelos y vistas creadas con DBT.

# Demo visual en Youtube

[![Demo Pipeline](https://img.youtube.com/vi/aOJAdJFkF28/0.jpg)](https://www.youtube.com/watch?v=aOJAdJFkF28)

### Observaciones

Ejecutar Airbyte con docker-compose y el script `run-ab-platform.sh` est谩 deprecado. Lo ideal ser铆a seguir la documentaci贸n para ejecutar Airbyte localmente con la nueva integraci贸n que hicieron con `abctl`, la cual se puede encontrar en el siguiente enlace [Airbyte Quickstart](https://docs.airbyte.com/using-airbyte/getting-started/oss-quickstart). 

Sin embargo, estuve presentando muchos problemas al intentar hacerlo con este 煤ltimo mencionado e investigando encontr茅 que es un bug que a煤n siguen investigando y que todav铆a no tienen soluci贸n. El screenshot del problema es el siguiente:

<img width="873" alt="Screenshot 2024-10-19 at 5 32 41PM" src="https://github.com/user-attachments/assets/a739c067-a2dc-4eb6-ab98-2d1b7989e53f">


M谩s informaci贸n sobre el ticket del issue [Aqu铆](https://docs.airbyte.com/deploying-airbyte/troubleshoot-deploy#failed-to-init-node-with-kubeadm)


